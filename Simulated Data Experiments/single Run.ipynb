{
 "cells": [
  {
   "cell_type": "code",
   "id": "2e1c53fd8ff0f350",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, QuantileRegressor\n",
    "from mapie.regression import MapieRegressor, MapieQuantileRegressor\n",
    "from mapie.conformity_scores import AbsoluteConformityScore, ResidualNormalisedScore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from mapie.metrics import regression_coverage_score\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to generate homoscedastic data with multiple features\n",
    "def generate_homoscedastic_data(n, m, beta, sigma, noise_scale=7):\n",
    "    X = np.random.uniform(0, 100, (n, m))\n",
    "    epsilon = np.random.normal(0, 1, n)\n",
    "    Y = X.dot(beta) + sigma * epsilon * noise_scale\n",
    "    return X, Y\n",
    "\n",
    "# Function to generate heteroscedastic data with multiple features\n",
    "def generate_heteroscedastic_data(n, m, beta, noise_scale=1):\n",
    "    X = np.random.uniform(0, 100, (n, m))\n",
    "    epsilon1 = np.random.normal(0, 1, n)\n",
    "    epsilon2 = np.random.normal(0, 1, n)\n",
    "    Z = X.dot(beta) + noise_scale * epsilon1\n",
    "    Y = Z * (1 + noise_scale * epsilon2)\n",
    "    return X, Y\n",
    "\n",
    "# Function to generate heteroscedastic sparse data with multiple features\n",
    "def generate_heteroscedastic_sparse_data(n, m, beta, noise_scale=1):\n",
    "    X = np.random.uniform(0, 100, (n, m))\n",
    "    mask_central = (X[:, 0] >= 25) & (X[:, 0] <= 75)\n",
    "    mask_outer = (X[:, 0] < 25) | (X[:, 0] > 75)\n",
    "    \n",
    "    # Reduce the number of points in the outer regions by keeping only a fraction of them\n",
    "    outer_indices = np.where(mask_outer)[0]\n",
    "    keep_outer_indices = np.random.choice(outer_indices, size=int(len(outer_indices) * 0.2), replace=False)\n",
    "    \n",
    "    # Combine the central and reduced outer indices\n",
    "    final_indices = np.concatenate([np.where(mask_central)[0], keep_outer_indices])\n",
    "    X = X[final_indices]\n",
    "    \n",
    "    epsilon1 = np.random.normal(0, 1, X.shape[0])\n",
    "    epsilon2 = np.random.normal(0, 1, X.shape[0])\n",
    "    Z = X.dot(beta) + noise_scale * epsilon1\n",
    "    Y = Z * (1 + noise_scale * epsilon2)\n",
    "    return X, Y"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Parameters\n",
    "n = 2000  # Number of samples\n",
    "m = 1     # Number of features\n",
    "beta = np.ones(m)  # Coefficients for the linear model\n",
    "sigma = 1.0\n",
    "\n",
    "# Generate datasets\n",
    "X1, Y1 = generate_homoscedastic_data(n, m, beta, sigma)\n",
    "X2, Y2 = generate_heteroscedastic_data(n, m, beta, noise_scale=0.2)\n",
    "X3, Y3 = generate_heteroscedastic_sparse_data(n, m, beta, noise_scale=0.2)\n",
    "\n",
    "datasets = [(X1, Y1, 'Homoscedastic'), (X2, Y2, 'Heteroscedastic'), (X3, Y3, 'Heteroscedastic Sparse')]\n",
    "\n",
    "# Function to train MAPIE models and evaluate\n",
    "def train_and_evaluate_mapie_models(X, Y, dataset_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=4)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # Linear Regression Model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # MAPIE Regressor with AbsoluteConformityScore\n",
    "    mapie_absolute = MapieRegressor(estimator=model, cv=\"split\", conformity_score=AbsoluteConformityScore())\n",
    "    mapie_absolute.fit(X_train, y_train)\n",
    "    y_pred_abs, y_pis_abs = mapie_absolute.predict(X_test, alpha=0.1)\n",
    "\n",
    "    mse_abs = mean_squared_error(y_test, y_pred_abs)\n",
    "    r2_abs = r2_score(y_test, y_pred_abs)\n",
    "    coverage_abs = regression_coverage_score(y_test, y_pis_abs[:, 0], y_pis_abs[:, 1])\n",
    "    avg_width_abs = np.mean(y_pis_abs[:, 1] - y_pis_abs[:, 0])\n",
    "    \n",
    "    results.append((dataset_name, 'AbsoluteConformityScore', mse_abs, r2_abs, coverage_abs, avg_width_abs))\n",
    "\n",
    "    # MAPIE Regressor with ResidualNormalisedScore\n",
    "    mapie_normalized = MapieRegressor(estimator=model, cv=\"split\", conformity_score=ResidualNormalisedScore())\n",
    "    mapie_normalized.fit(X_train, y_train)\n",
    "    y_pred_norm, y_pis_norm = mapie_normalized.predict(X_test, alpha=0.1)\n",
    "\n",
    "    mse_norm = mean_squared_error(y_test, y_pred_norm)\n",
    "    r2_norm = r2_score(y_test, y_pred_norm)\n",
    "    coverage_norm = regression_coverage_score(y_test, y_pis_norm[:, 0], y_pis_norm[:, 1])\n",
    "    avg_width_norm = np.mean(y_pis_norm[:, 1] - y_pis_norm[:, 0])\n",
    "    \n",
    "    results.append((dataset_name, 'ResidualNormalisedScore', mse_norm, r2_norm, coverage_norm, avg_width_norm))\n",
    "\n",
    "    # Conformal Quantile Regression (CQR)\n",
    "    quantile_model = QuantileRegressor(quantile=0.5, solver='highs')\n",
    "    mapie_cqr = MapieQuantileRegressor(estimator=quantile_model, cv=\"split\", alpha=0.1)\n",
    "    mapie_cqr.fit(X_train, y_train)\n",
    "    y_pred_cqr, y_pis_cqr = mapie_cqr.predict(X_test)\n",
    "\n",
    "    mse_cqr = mean_squared_error(y_test, y_pred_cqr)\n",
    "    r2_cqr = r2_score(y_test, y_pred_cqr)\n",
    "    coverage_cqr = regression_coverage_score(y_test, y_pis_cqr[:, 0, 0], y_pis_cqr[:, 1, 0])\n",
    "    avg_width_cqr = np.mean(y_pis_cqr[:, 1, 0] - y_pis_cqr[:, 0, 0])\n",
    "    \n",
    "    results.append((dataset_name, 'ConformalQuantileRegression', mse_cqr, r2_cqr, coverage_cqr, avg_width_cqr))\n",
    "\n",
    "    return results, X_test, y_test, y_pred_abs, y_pis_abs, y_pred_norm, y_pis_norm, y_pred_cqr, y_pis_cqr\n"
   ],
   "id": "bd9baef0a6da55ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Function to plot prediction comparisons\n",
    "def plot_predictions_comparison(datasets, train_and_evaluate_fn):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    covered_color = 'blue'  # Color for covered data points\n",
    "    uncovered_color = 'red'  # Color for uncovered data points\n",
    "\n",
    "    # Loop through each dataset\n",
    "    for X, Y, dataset_name in datasets:\n",
    "        results, X_test, y_test, y_pred_abs, y_pis_abs, y_pred_norm, y_pis_norm, y_pred_cqr, y_pis_cqr = train_and_evaluate_fn(X, Y, dataset_name)\n",
    "        \n",
    "        # Ensure y_pis are correctly flattened\n",
    "        y_pis_abs = y_pis_abs.squeeze()\n",
    "        y_pis_norm = y_pis_norm.squeeze()\n",
    "        y_pis_cqr = y_pis_cqr.squeeze()\n",
    "\n",
    "        # Create a figure with three subplots\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "        # Define coverage for each plot\n",
    "        covered_abs = (y_test >= y_pis_abs[:, 0]) & (y_test <= y_pis_abs[:, 1])\n",
    "        covered_norm = (y_test >= y_pis_norm[:, 0]) & (y_test <= y_pis_norm[:, 1])\n",
    "        covered_cqr = (y_test >= y_pis_cqr[:, 0]) & (y_test <= y_pis_cqr[:, 1])\n",
    "        \n",
    "        # Uniform representation of data points and plots\n",
    "        for i, (pred, covered, title) in enumerate(zip(\n",
    "            [y_pred_abs, y_pred_norm, y_pred_cqr],\n",
    "            [covered_abs, covered_norm, covered_cqr],\n",
    "            ['AbsoluteConformityScore', 'ResidualNormalisedScore', 'ConformalQuantileRegression'])):\n",
    "            sns.scatterplot(x=y_test, y=pred, hue=covered, palette={True: covered_color, False: uncovered_color}, ax=axes[i], legend=(i==2))\n",
    "            axes[i].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "            axes[i].set_title(f'{title} - Coverage={np.mean(covered)*100:.1f}%')\n",
    "            axes[i].set_xlabel('Actual Target')\n",
    "            axes[i].set_ylabel('Predicted Target')\n",
    "            axes[i].set_ylim(0, 120)\n",
    "        \n",
    "        # Display legend only in the last plot\n",
    "        if i == 2:\n",
    "            handles, labels = axes[i].get_legend_handles_labels()\n",
    "            labels = ['Uncovered', 'Covered']\n",
    "            axes[i].legend(handles=handles, labels=labels, title='Prediction Coverage')\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(f'{dataset_name}_predictions_comparison.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate prediction interval width for each model approach\n",
    "        interval_width_abs = y_pis_abs[:, 1] - y_pis_abs[:, 0]\n",
    "        interval_width_norm = y_pis_norm[:, 1] - y_pis_norm[:, 0]\n",
    "        interval_width_cqr = y_pis_cqr[:, 1] - y_pis_cqr[:, 0]\n",
    "    \n",
    "        # Create plots for prediction interval width\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(24, 6), sharey=True)\n",
    "        \n",
    "        # Plot for AbsoluteConformityScore\n",
    "        sns.scatterplot(x=y_test, y=interval_width_abs, hue=covered_abs, palette={True: covered_color, False: uncovered_color}, ax=axes[0])\n",
    "        axes[0].set_xlabel('Actual Target (y)')\n",
    "        axes[0].set_title('AbsoluteConformityScore - Interval Width')\n",
    "        axes[0].set_ylabel('Prediction Interval Width (Î”y)')\n",
    "        axes[0].set_ylim(0, 100)  # Optional: adjust y-limit\n",
    "        axes[0].legend([],[], frameon=False)  # Suppress the legend\n",
    "        \n",
    "        # Plot for ResidualNormalisedScore\n",
    "        sns.scatterplot(x=y_test, y=interval_width_norm, hue=covered_norm, palette={True: covered_color, False: uncovered_color}, ax=axes[1])\n",
    "        axes[1].set_xlabel('Actual Target (y)')\n",
    "        axes[1].set_title('ResidualNormalisedScore - Interval Width')\n",
    "        axes[1].set_ylim(0, 100)  # Optional: adjust y-limit\n",
    "        axes[1].legend([],[], frameon=False)  # Suppress the legend\n",
    "        \n",
    "        # Plot for ConformalQuantileRegression\n",
    "        sns.scatterplot(x=y_test, y=interval_width_cqr, hue=covered_cqr, palette={True: covered_color, False: uncovered_color}, ax=axes[2])\n",
    "        axes[2].set_xlabel('Actual Target (y)')\n",
    "        axes[2].set_title('ConformalQuantileRegression - Interval Width')\n",
    "        axes[2].set_ylim(0, 100)  # Optional: adjust y-limit\n",
    "        # This plot shows the legend to represent coverage (Covered/Uncovered)\n",
    "        handles, labels = axes[2].get_legend_handles_labels()\n",
    "        axes[2].legend(handles=handles, labels=['Uncovered', 'Covered'], title='Prediction Coverage')\n",
    "\n",
    "        if i < 2:  # No legend for the first two plots\n",
    "            axes[i].legend([],[], frameon=False)  # Empty legend\n",
    "        else:  # Full legend for the last plot\n",
    "            handles, labels = axes[i].get_legend_handles_labels()\n",
    "            labels = ['Uncovered', 'Covered']\n",
    "            axes[i].legend(handles=handles, labels=labels, title='Prediction Coverage')\n",
    "            plt.savefig(f'{dataset_name}_interval_width_comparison.png')\n",
    "        \n",
    "        # Calculate local coverage values for each interval\n",
    "        quantiles = np.percentile(y_test, np.arange(0, 101, 10))\n",
    "        local_coverage_abs = []\n",
    "        local_coverage_norm = []\n",
    "        local_coverage_cqr = []\n",
    "    \n",
    "        for i in range(len(quantiles)-1):\n",
    "            mask = (y_test >= quantiles[i]) & (y_test < quantiles[i+1])\n",
    "            local_coverage_abs.append(np.mean((y_test[mask] >= y_pis_abs[mask, 0]) & (y_test[mask] <= y_pis_abs[mask, 1])))\n",
    "            local_coverage_norm.append(np.mean((y_test[mask] >= y_pis_norm[mask, 0]) & (y_test[mask] <= y_pis_norm[mask, 1])))\n",
    "            local_coverage_cqr.append(np.mean((y_test[mask] >= y_pis_cqr[mask, 0]) & (y_test[mask] <= y_pis_cqr[mask, 1])))\n",
    "    \n",
    "        # Visualization of local coverage for each prediction method\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(24, 6), sharey=True)\n",
    "        sns.barplot(x=np.arange(10), y=local_coverage_abs, ax=axes[0], palette=['#1f77b4'])  # Blue for Homoscedastic\n",
    "        sns.barplot(x=np.arange(10), y=local_coverage_norm, ax=axes[1], palette=['#ff7f0e'])  # Orange for Heteroscedastic\n",
    "        sns.barplot(x=np.arange(10), y=local_coverage_cqr, ax=axes[2], palette=['#2ca02c'])  # Green for Heteroscedastic Sparse\n",
    "\n",
    "        # Setting up the plots\n",
    "        for i, title in enumerate(['AbsoluteConformityScore', 'ResidualNormalisedScore', 'ConformalQuantileRegression']):\n",
    "            axes[i].set_xticks(range(10))\n",
    "            axes[i].set_xticklabels([f'{int(quantiles[j])}-{int(quantiles[j+1])}' for j in range(10)], rotation=45)\n",
    "            axes[i].set_xlabel('Target Quantile (q)')\n",
    "            axes[i].set_ylabel('Coverage Score' if i == 0 else \"\")\n",
    "            axes[i].axhline(y=np.mean([local_coverage_abs, local_coverage_norm, local_coverage_cqr][i]), color='r', linestyle='--', label='Global Coverage')\n",
    "            axes[i].legend()\n",
    "            axes[i].set_ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{dataset_name}_local_coverage_comparison.png')\n",
    "        plt.show()"
   ],
   "id": "e7bfe069d09b2a2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Example (train_and_evaluate_mapie_models and datasets must be defined)\n",
    "plot_predictions_comparison(datasets, train_and_evaluate_mapie_models)\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c7fcc35f8ec3f41f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
